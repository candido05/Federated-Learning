# Federated Learning com OtimizaÃ§Ã£o SDN

## ğŸ“š Sobre o Projeto

Este repositÃ³rio contÃ©m o **Trabalho de ConclusÃ£o de Curso (TCC)** intitulado **"OtimizaÃ§Ã£o de Modelos de Aprendizado Federado com SDN (Software-Defined Networking)"**, desenvolvido como requisito para obtenÃ§Ã£o do grau de Bacharel em CiÃªncia da ComputaÃ§Ã£o pela Universidade Federal da ParaÃ­ba (UFPB).

### Autor
**CÃ¢ndido Leandro de Queiroga Bisneto**

### Orientador
**Prof. Fernando Menezes Matos**

---

## ğŸ¯ Objetivos da Pesquisa

O TCC tem como objetivo principal investigar e avaliar o desempenho de **modelos baseados em Ã¡rvores de decisÃ£o** (XGBoost, LightGBM e CatBoost) em ambientes de **Aprendizado Federado**, com foco em:

1. **ImplementaÃ§Ã£o de modelos tree-based em FL**: Adaptar XGBoost, LightGBM e CatBoost para funcionarem no framework Flower
2. **OtimizaÃ§Ã£o com SDN**: Integrar Software-Defined Networking para otimizar comunicaÃ§Ã£o entre clientes e servidor
3. **AnÃ¡lise de cenÃ¡rios IID vs non-IID**: Comparar desempenho em distribuiÃ§Ãµes de dados homogÃªneas e heterogÃªneas
4. **AvaliaÃ§Ã£o de estratÃ©gias de agregaÃ§Ã£o**: Testar diferentes algoritmos (FedAvg, FedProx, FedAdam, etc.)
5. **MÃ©tricas de desempenho**: Analisar acurÃ¡cia, tempo de convergÃªncia, overhead de comunicaÃ§Ã£o, latÃªncia e consumo de banda

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```
Federated-Learning/
â”œâ”€â”€ doc/                          # ğŸ“„ DOCUMENTAÃ‡ÃƒO DO TCC (PRINCIPAL)
â”‚   â”œâ”€â”€ main.tex                  # Documento principal LaTeX
â”‚   â”œâ”€â”€ chapters/                 # CapÃ­tulos da monografia
â”‚   â”‚   â”œâ”€â”€ 01_introducao.tex
â”‚   â”‚   â”œâ”€â”€ 02_revisao_literatura.tex
â”‚   â”‚   â”œâ”€â”€ 03_fundamentos_teoricos.tex
â”‚   â”‚   â”œâ”€â”€ 04_metodologia.tex
â”‚   â”‚   â”œâ”€â”€ 05_dataset.tex
â”‚   â”‚   â”œâ”€â”€ 06_config_experimental.tex
â”‚   â”‚   â”œâ”€â”€ 07_resultados.tex
â”‚   â”‚   â”œâ”€â”€ 08_discussao.tex
â”‚   â”‚   â””â”€â”€ 09_conclusao.tex
â”‚   â”œâ”€â”€ pre_textual/              # Elementos prÃ©-textuais
â”‚   â”œâ”€â”€ figures/                  # Imagens e logos
â”‚   â”œâ”€â”€ tables/                   # Tabelas de resultados
â”‚   â”œâ”€â”€ tcc.cls                   # Classe LaTeX customizada
â”‚   â””â”€â”€ Makefile                  # CompilaÃ§Ã£o automÃ¡tica
â”‚
â”œâ”€â”€ Code/                         # ğŸ’» CÃ“DIGO-FONTE
â”‚   â”œâ”€â”€ ml_code/                  # â­ BASE PARA IMPLEMENTAÃ‡ÃƒO DO TCC
â”‚   â”‚   â”œâ”€â”€ models.py             # Wrapper para modelos ML (ESTENDER AQUI!)
â”‚   â”‚   â”œâ”€â”€ client.py             # Cliente Flower para ML tradicional
â”‚   â”‚   â”œâ”€â”€ server.py             # Servidor FL com estratÃ©gias
â”‚   â”‚   â”œâ”€â”€ data_loader.py        # Carregamento e particionamento de dados
â”‚   â”‚   â”œâ”€â”€ visualization.py      # VisualizaÃ§Ã£o de resultados
â”‚   â”‚   â””â”€â”€ main.py               # Script principal de execuÃ§Ã£o
â”‚   â”‚
â”‚   â””â”€â”€ nn_code/                  # ImplementaÃ§Ã£o com Redes Neurais (referÃªncia)
â”‚       â”œâ”€â”€ models.py             # ResNet, EfficientNet, MobileNet
â”‚       â”œâ”€â”€ client.py             # Cliente FL para PyTorch
â”‚       â”œâ”€â”€ server.py             # Servidor com seleÃ§Ã£o baseada em VRAM
â”‚       â””â”€â”€ main.py               # ExecuÃ§Ã£o de experimentos
â”‚
â”œâ”€â”€ CLAUDE.md                     # Guia para Claude Code (instruÃ§Ãµes de desenvolvimento)
â””â”€â”€ README.md                     # Este arquivo
```

---

## ğŸš€ ImplementaÃ§Ã£o Atual vs. Planejada

### âœ… CÃ³digo Existente (ProtÃ³tipos)

#### 1. `Code/ml_code/` - **Modelos Tradicionais de ML**
ImplementaÃ§Ã£o base com **Flower framework** contendo:
- **Modelos atuais**: Random Forest, SVM, Logistic Regression, KNN, Naive Bayes
- **Dataset**: MNIST (28Ã—28 flattened para 784 features)
- **EstratÃ©gias FL**: FedAvg, FedProx, FedAdam, FedAdagrad, FedYogi, FedMedian
- **Funcionalidades**: SerializaÃ§Ã£o pickle, particionamento IID, visualizaÃ§Ã£o de resultados

#### 2. `Code/nn_code/` - **Redes Neurais** (ReferÃªncia)
ImplementaÃ§Ã£o com PyTorch:
- **Modelos**: ResNet, EfficientNetV2, MobileNetV3
- **Recurso Ãºnico**: SeleÃ§Ã£o de clientes baseada em VRAM disponÃ­vel
- **Uso**: Apenas como referÃªncia, nÃ£o serÃ¡ usado no TCC

### ğŸ”¨ A Ser Implementado para o TCC

#### **Fase 1: Modelos Tree-Based** (PRIORITÃRIO)
Estender `Code/ml_code/models.py` para incluir:
```python
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
```

**Tarefas**:
- [ ] Adicionar XGBoost ao `_create_model()` em `models.py`
- [ ] Adicionar LightGBM ao `_create_model()` em `models.py`
- [ ] Adicionar CatBoost ao `_create_model()` em `models.py`
- [ ] Testar serializaÃ§Ã£o pickle para cada modelo
- [ ] Validar funcionamento em ambiente FL

#### **Fase 2: Dataset Tabular**
**Requisito**: CapÃ­tulo 5 do TCC deve ser completado primeiro

**Tarefas**:
- [ ] Selecionar dataset tabular adequado (UCI, Kaggle)
- [ ] Documentar metadados no CapÃ­tulo 5
- [ ] Implementar carregamento em `data_loader.py`
- [ ] Criar particionamento non-IID (Dirichlet)
- [ ] Validar distribuiÃ§Ã£o IID vs non-IID

#### **Fase 3: IntegraÃ§Ã£o SDN**
**Objetivo**: Otimizar comunicaÃ§Ã£o FL com polÃ­ticas de QoS

**Tarefas**:
- [ ] Definir controlador SDN (OpenFlow)
- [ ] Implementar monitoramento de rede (latÃªncia, throughput)
- [ ] Criar polÃ­ticas de priorizaÃ§Ã£o de trÃ¡fego FL
- [ ] Comparar FL com/sem SDN
- [ ] Coletar mÃ©tricas de overhead de comunicaÃ§Ã£o

#### **Fase 4: Experimentos e AnÃ¡lise**
**Tarefas**:
- [ ] Executar grid search de hiperparÃ¢metros
- [ ] Rodar experimentos: {XGBoost, LightGBM, CatBoost} Ã— {FedAvg, FedProx, FedAdam} Ã— {IID, non-IID}
- [ ] Coletar mÃ©tricas: accuracy, precision, recall, F1, AUC-ROC
- [ ] AnÃ¡lise estatÃ­stica (Friedman + Nemenyi)
- [ ] Gerar grÃ¡ficos de convergÃªncia
- [ ] Preencher CapÃ­tulo 7 (Resultados)

---

## ğŸ› ï¸ Como Executar

### PrÃ©-requisitos
```bash
# Python 3.9+
pip install flwr>=1.6.0
pip install xgboost>=2.0.0      # A INSTALAR
pip install lightgbm>=4.0.0     # A INSTALAR
pip install catboost>=1.2.0     # A INSTALAR
pip install scikit-learn>=1.3.0
pip install numpy pandas matplotlib seaborn
```

### Executar ProtÃ³tipo Atual (ML Tradicional)
```bash
cd Code/ml_code
python main.py

# Menu interativo:
# 1. Todos os experimentos (todos modelos Ã— todas estratÃ©gias)
# 2. Experimentos especÃ­ficos (editar main.py linhas 159-161)
# 3. Experimento Ãºnico
```

### ConfiguraÃ§Ã£o de Experimentos
Editar `Code/ml_code/main.py`:
```python
NUM_PARTITIONS = 10   # NÃºmero de clientes FL
NUM_ROUNDS = 20       # Rodadas de treinamento
BATCH_SIZE = 2        # Tamanho do batch local

# Para TCC (apÃ³s implementar tree-based models):
selected_models = ["xgboost", "lightgbm", "catboost"]
selected_strategies = ["FedAvg", "FedProx", "FedAdam"]
```

---

## ğŸ“– DocumentaÃ§Ã£o do TCC

### Compilar LaTeX
```bash
cd doc
latexmk -pdf main.tex    # CompilaÃ§Ã£o completa com auto-referÃªncias
make                     # Alternativa com Makefile
make watch               # Auto-recompilaÃ§Ã£o ao salvar arquivos
```

### Status de Preenchimento
O documento possui **~180 placeholders** `<<...>>` a serem preenchidos. Progresso por capÃ­tulo:

| CapÃ­tulo | Status | Placeholders | Prioridade |
|----------|--------|--------------|------------|
| 1. IntroduÃ§Ã£o | ğŸ“ Rascunho | ~15 | MÃ©dia |
| 2. RevisÃ£o de Literatura | ğŸ“ Rascunho | ~20 | Alta |
| 3. Fundamentos TeÃ³ricos | ğŸ“ Rascunho | ~25 | Alta |
| 4. Metodologia | ğŸ“ Rascunho | ~25 | Alta |
| 5. Dataset | âš ï¸ Pendente | ~50 | **CRÃTICA** |
| 6. ConfiguraÃ§Ã£o Experimental | ğŸ“ Rascunho | ~20 | Alta |
| 7. Resultados | âš ï¸ Pendente | ~30 | **CRÃTICA** |
| 8. DiscussÃ£o | ğŸ“ Rascunho | ~10 | MÃ©dia |
| 9. ConclusÃ£o | ğŸ“ Rascunho | ~5 | Baixa |

**Legenda**: âš ï¸ Pendente de dados experimentais | ğŸ“ Estrutura criada

### Encontrar Placeholders
```bash
cd doc
grep -r "<<" chapters/          # Listar todos os placeholders
grep "<<" chapters/05_dataset.tex | wc -l  # Contar no CapÃ­tulo 5
```

---

## ğŸ”¬ Metodologia de Pesquisa

### Frameworks e Tecnologias
- **Federated Learning**: [Flower](https://flower.dev/) 1.6+
- **Modelos**: XGBoost, LightGBM, CatBoost
- **Linguagem**: Python 3.9+
- **SDN**: A definir (OpenFlow/Ryu/ONOS)
- **ComunicaÃ§Ã£o**: gRPC (padrÃ£o do Flower)

### CenÃ¡rios de Teste
1. **IID (Independent and Identically Distributed)**: Dados distribuÃ­dos uniformemente entre clientes
2. **Non-IID**: DistribuiÃ§Ã£o heterogÃªnea usando Dirichlet (Î± = 0.5)

### MÃ©tricas de AvaliaÃ§Ã£o
- **Desempenho do Modelo**: Accuracy, Precision, Recall, F1-Score, AUC-ROC
- **ConvergÃªncia**: NÃºmero de rodadas atÃ© atingir acurÃ¡cia alvo
- **ComunicaÃ§Ã£o**: Bytes transmitidos por rodada, overhead total
- **Rede**: LatÃªncia, throughput, packet loss (com SDN)

---

## ğŸ“… Cronograma

| Fase | DescriÃ§Ã£o | Status |
|------|-----------|--------|
| âœ… 1 | Estrutura do TCC e revisÃ£o bibliogrÃ¡fica | ConcluÃ­do |
| âœ… 2 | ProtÃ³tipo com modelos tradicionais ML | ConcluÃ­do |
| ğŸ”„ 3 | ImplementaÃ§Ã£o de XGBoost/LightGBM/CatBoost | Em andamento |
| â³ 4 | SeleÃ§Ã£o e preparaÃ§Ã£o do dataset tabular | Pendente |
| â³ 5 | IntegraÃ§Ã£o com SDN | Pendente |
| â³ 6 | ExecuÃ§Ã£o de experimentos | Pendente |
| â³ 7 | AnÃ¡lise de resultados e escrita final | Pendente |
| â³ 8 | Defesa do TCC | Dezembro/2025 |

---

## ğŸ“ LicenÃ§a

Este projeto Ã© desenvolvido para fins acadÃªmicos como parte do Trabalho de ConclusÃ£o de Curso do Centro de InformÃ¡tica da UFPB.

---

## ğŸ“§ Contato

Para dÃºvidas sobre o projeto:
- **Autor**: CÃ¢ndido Leandro de Queiroga Bisneto
- **InstituiÃ§Ã£o**: Centro de InformÃ¡tica - UFPB
- **Orientador**: Prof. Fernando Menezes Matos

---

## ğŸ™ Agradecimentos

- Centro de InformÃ¡tica da UFPB
- Flower Framework Community
- Comunidades de cÃ³digo aberto XGBoost, LightGBM e CatBoost

---

**Ãšltima atualizaÃ§Ã£o**: Outubro/2025
